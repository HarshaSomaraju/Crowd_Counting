{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee2143c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69de5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfc62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, ftrs):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.ftrs = ftrs\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(128, 1, 1), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ftrs(x)\n",
    "        x = torch.nn.functional.upsample_bilinear(x, scale_factor=2)\n",
    "        x = self.layer2(x)\n",
    "        mu = self.layer3(x)\n",
    "        B, C, H, W = mu.size()\n",
    "        mu_sum = mu.view([B, -1]).sum(1).unsqueeze(1).unsqueeze(2).unsqueeze(3)\n",
    "        mu_norm = mu / (mu_sum + 1000000)\n",
    "        return mu, mu_norm\n",
    "\n",
    "def make_model(config):\n",
    "    lyrs = []\n",
    "    in_ch = 3\n",
    "    for v in config:\n",
    "        if v == 'M':\n",
    "            lyrs += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_ch, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                lyrs += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                lyrs += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_ch = v\n",
    "    return nn.Sequential(*lyrs)\n",
    "\n",
    "config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512]\n",
    "\n",
    "def vgg19():\n",
    "    model = VGG19(make_model(config))\n",
    "    model.load_state_dict(model_zoo.load_url('https://download.pytorch.org/models/vgg19-dcbb9e9d.pth'), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99187748",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52c9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2c068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropper(h, w, ch, cw): \n",
    "    out_w = w - cw\n",
    "    out_h = h - ch\n",
    "    i = random.randint(0, out_h)\n",
    "    j = random.randint(0, out_w)\n",
    "    return i, j, ch, cw\n",
    "\n",
    "\n",
    "def gen_discrete_map(h, w, points):\n",
    "    discrete_map = np.zeros([h, w], dtype=np.float32)\n",
    "    no_gt = points.shape[0]\n",
    "    if no_gt == 0:\n",
    "        return discrete_map\n",
    "    points_np = np.array(points).round().astype(int)\n",
    "    p_h = np.minimum(points_np[:, 1], np.array([h-1]*no_gt).astype('int64'))\n",
    "    p_w = np.minimum(points_np[:, 0], np.array([w-1]*no_gt).astype('int64'))\n",
    "    p_index = torch.from_numpy(p_h* im_width + p_w)\n",
    "\n",
    "    discrete_map = torch.zeros(w * h).scatter_add_(0, index=p_index, src=torch.ones(w*h)).view(h, w).numpy()\n",
    "    assert np.sum(discrete_map) == no_gt\n",
    "    return discrete_map\n",
    "    \n",
    "class Custom_dataloader():\n",
    "    def __init__(self, path, csize, downsample_ratio=8, method='train'):\n",
    "        self.path = path\n",
    "        self.csize = csize\n",
    "        self.d_ratio = downsample_ratio\n",
    "        assert self.csize % self.d_ratio == 0\n",
    "        self.dc_size = self.csize // self.d_ratio\n",
    "        self.trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "        self.images = sorted(glob(os.path.join(self.path, 'images', '*.jpg')))\n",
    "        print(f'Total images: {len(self.images)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_path = self.images[item]\n",
    "        name = os.path.basename(img_path).split('.')[0]\n",
    "        gd_path = os.path.join(self.path, 'ground-truth', 'GT_{}.mat'.format(name))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        keypoints = sio.loadmat(gd_path)['image_info'][0][0][0][0][0]\n",
    "\n",
    "        if self.method == 'train':\n",
    "            return self.train_transform(img, keypoints)\n",
    "        elif self.method == 'val':\n",
    "            img = self.trans(img)\n",
    "            img.resize_((3, 225, 225))\n",
    "            return img, len(keypoints), name\n",
    "\n",
    "    def train_transform(self, img, keypoints):\n",
    "        wd, ht = img.size\n",
    "        st_size = 1.0 * min(wd, ht)\n",
    "        if st_size < self.csize:\n",
    "            rr = 1.0 * self.csize / st_size\n",
    "            wd = round(wd * rr)\n",
    "            ht = round(ht * rr)\n",
    "            st_size = 1.0 * min(wd, ht)\n",
    "            img = img.resize((wd, ht), Image.BICUBIC)\n",
    "            keypoints = keypoints * rr\n",
    "        assert st_size >= self.csize, print(wd, ht)\n",
    "        assert len(keypoints) >= 0\n",
    "        i, j, h, w = cropper(ht, wd, self.csize, self.csize)\n",
    "        img = torchvision.transforms.functional.crop(img, i, j, h, w)\n",
    "        if len(keypoints) > 0:\n",
    "            keypoints = keypoints - [j, i]\n",
    "            idx_mask = (keypoints[:, 0] >= 0) * (keypoints[:, 0] <= w) * \\\n",
    "                       (keypoints[:, 1] >= 0) * (keypoints[:, 1] <= h)\n",
    "            keypoints = keypoints[idx_mask]\n",
    "        else:\n",
    "            keypoints = np.empty([0, 2])\n",
    "\n",
    "        gt_discrete = gen_discrete_map(h, w, keypoints)\n",
    "        down_w = w // self.d_ratio\n",
    "        down_h = h // self.d_ratio\n",
    "        gt_discrete = gt_discrete.reshape([down_h, self.d_ratio, down_w, self.d_ratio]).sum(axis=(1, 3))\n",
    "        assert np.sum(gt_discrete) == len(keypoints)\n",
    "\n",
    "        if len(keypoints) > 0:\n",
    "            if random.random() > 0.5:\n",
    "                img = torchvision.transforms.functional.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "                keypoints[:, 0] = w - keypoints[:, 0] - 1\n",
    "        else:\n",
    "            if random.random() > 0.5:\n",
    "                img = torchvision.transforms.functional.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "        gt_discrete = np.expand_dims(gt_discrete, 0)\n",
    "        \n",
    "\n",
    "        return self.trans(img), torch.from_numpy(keypoints.copy()).float(), torch.from_numpy(\n",
    "            gt_discrete.copy()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9504298",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47789e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfb4e8",
   "metadata": {},
   "source": [
    "###  Helper modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79d5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def get_logger(log_file):\n",
    "    logger = logging.getLogger(log_file)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    fh = logging.FileHandler(log_file)\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    ch.setFormatter(formatter)\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def print_config(config, logger):\n",
    "    for k, v in config.items():\n",
    "        logger.info(\"{}:\\t{}\".format(k.ljust(15), v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adbc9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, decay_epoch=10):\n",
    "\n",
    "    lr = max(initial_lr * (0.1 ** (epoch // decay_epoch)), 1e-6)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class Save_Handle(object):\n",
    "    def __init__(self, max_num):\n",
    "        self.save_list = []\n",
    "        self.max_num = max_num\n",
    "\n",
    "    def append(self, save_path):\n",
    "        if len(self.save_list) < self.max_num:\n",
    "            self.save_list.append(save_path)\n",
    "        else:\n",
    "            remove_path = self.save_list[0]\n",
    "            del self.save_list[0]\n",
    "            self.save_list.append(save_path)\n",
    "            if os.path.exists(remove_path):\n",
    "                os.remove(remove_path)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = 1.0 * self.sum / self.count\n",
    "\n",
    "    def get_avg(self):\n",
    "        return self.avg\n",
    "\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "\n",
    "\n",
    "def set_trainable(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "def get_num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3fc4c1",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0fa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "M_EPS = 1e-16\n",
    "\n",
    "def sinkhorn(a, b, C, reg=1e-1, maxIter=1000, stopThr=1e-9,\n",
    "                   verbose=False, log=False, warm_start=None, eval_freq=10, print_freq=200, **kwargs):\n",
    "\n",
    "    device = a.device\n",
    "    na, nb = C.shape\n",
    "\n",
    "    assert na >= 1 and nb >= 1, 'C needs to be 2d'\n",
    "    assert na == a.shape[0] and nb == b.shape[0], \"Shape of a or b does't match that of C\"\n",
    "    assert reg > 0, 'reg should be greater than 0'\n",
    "    assert a.min() >= 0. and b.min() >= 0., 'Elements in a or b less than 0'\n",
    "\n",
    "    if log:\n",
    "        log = {'err': []}\n",
    "\n",
    "    if warm_start is not None:\n",
    "        u = warm_start['u']\n",
    "        v = warm_start['v']\n",
    "    else:\n",
    "        u = torch.ones(na, dtype=a.dtype).to(device) / na\n",
    "        v = torch.ones(nb, dtype=b.dtype).to(device) / nb\n",
    "\n",
    "    K = torch.empty(C.shape, dtype=C.dtype).to(device)\n",
    "    torch.div(C, -reg, out=K)\n",
    "    torch.exp(K, out=K)\n",
    "\n",
    "    b_hat = torch.empty(b.shape, dtype=C.dtype).to(device)\n",
    "\n",
    "    it = 1\n",
    "    err = 1\n",
    "\n",
    "    KTu = torch.empty(v.shape, dtype=v.dtype).to(device)\n",
    "    Kv = torch.empty(u.shape, dtype=u.dtype).to(device)\n",
    "\n",
    "    while (err > stopThr and it <= maxIter):\n",
    "        upre, vpre = u, v\n",
    "        torch.matmul(u, K, out=KTu)\n",
    "        v = torch.div(b, KTu + M_EPS)\n",
    "        torch.matmul(K, v, out=Kv)\n",
    "        u = torch.div(a, Kv + M_EPS)\n",
    "\n",
    "        if torch.any(torch.isnan(u)) or torch.any(torch.isnan(v)) or \\\n",
    "                torch.any(torch.isinf(u)) or torch.any(torch.isinf(v)):\n",
    "            print('Warning: numerical errors at iteration', it)\n",
    "            u, v = upre, vpre\n",
    "            break\n",
    "\n",
    "        if log and it % eval_freq == 0:\n",
    "            b_hat = torch.matmul(u, K) * v\n",
    "            err = (b - b_hat).pow(2).sum().item()\n",
    "            log['err'].append(err)\n",
    "\n",
    "        if verbose and it % print_freq == 0:\n",
    "            print('iteration {:5d}, constraint error {:5e}'.format(it, err))\n",
    "\n",
    "        it += 1\n",
    "\n",
    "    if log:\n",
    "        log['u'] = u\n",
    "        log['v'] = v\n",
    "        log['alpha'] = reg * torch.log(u + M_EPS)\n",
    "        log['beta'] = reg * torch.log(v + M_EPS)\n",
    "\n",
    "    # transport plan\n",
    "    P = u.reshape(-1, 1) * K * v.reshape(1, -1)\n",
    "    if log:\n",
    "        return P, log\n",
    "    else:\n",
    "        return P\n",
    "\n",
    "class OT_Loss(Module):\n",
    "    def __init__(self, csize, stride, norm_cood, device, num_of_iter_in_ot=100, reg=10.0):\n",
    "        super(OT_Loss, self).__init__()\n",
    "        assert csize % stride == 0\n",
    "\n",
    "        self.csize = csize\n",
    "        self.device = device\n",
    "        self.norm_cood = norm_cood\n",
    "        self.num_of_iter_in_ot = num_of_iter_in_ot\n",
    "        self.reg = reg\n",
    "\n",
    "\n",
    "        self.cood = torch.arange(0, csize, step=stride,\n",
    "                                 dtype=torch.float32, device=device) + stride / 2\n",
    "        self.density_size = self.cood.size(0)\n",
    "        self.cood.unsqueeze_(0) \n",
    "        if self.norm_cood:\n",
    "            self.cood = self.cood / csize * 2 - 1 \n",
    "        self.output_size = self.cood.size(1)\n",
    "\n",
    "\n",
    "    def forward(self, normed_density, unnormed_density, points):\n",
    "        batch_size = normed_density.size(0)\n",
    "        assert len(points) == batch_size\n",
    "        assert self.output_size == normed_density.size(2)\n",
    "        loss = torch.zeros([1]).to(self.device)\n",
    "        ot_obj_values = torch.zeros([1]).to(self.device)\n",
    "        wd = 0 \n",
    "        for idx, im_points in enumerate(points):\n",
    "            if len(im_points) > 0:\n",
    "                if self.norm_cood:\n",
    "                    im_points = im_points / self.csize * 2 - 1 \n",
    "                x = im_points[:, 0].unsqueeze_(1)  \n",
    "                y = im_points[:, 1].unsqueeze_(1)\n",
    "                x_dis = -2 * torch.matmul(x, self.cood) + x * x + self.cood * self.cood \n",
    "                y_dis = -2 * torch.matmul(y, self.cood) + y * y + self.cood * self.cood\n",
    "                y_dis.unsqueeze_(2)\n",
    "                x_dis.unsqueeze_(1)\n",
    "                dis = y_dis + x_dis\n",
    "                dis = dis.view((dis.size(0), -1)) \n",
    "                source_prob = normed_density[idx][0].view([-1]).detach()\n",
    "                target_prob = (torch.ones([len(im_points)]) / len(im_points)).to(self.device)\n",
    "\n",
    "                P, log = sinkhorn(target_prob, source_prob, dis, self.reg, maxIter=self.num_of_iter_in_ot, log=True)\n",
    "                beta = log['beta'] \n",
    "                ot_obj_values += torch.sum(normed_density[idx] * beta.view([1, self.output_size, self.output_size]))\n",
    "\n",
    "                source_density = unnormed_density[idx][0].view([-1]).detach()\n",
    "                source_count = source_density.sum()\n",
    "                im_grad_1 = (source_count) / (source_count * source_count+1e-8) * beta \n",
    "                im_grad_2 = (source_density * beta).sum() / (source_count * source_count + 1e-8) \n",
    "                im_grad = im_grad_1 - im_grad_2\n",
    "                im_grad = im_grad.detach().view([1, self.output_size, self.output_size])\n",
    "\n",
    "                loss += torch.sum(unnormed_density[idx] * im_grad)\n",
    "                wd += torch.sum(dis * P).item()\n",
    "\n",
    "        return loss, wd, ot_obj_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f50c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate(batch):\n",
    "    transposed_batch = list(zip(*batch))\n",
    "    images = torch.stack(transposed_batch[0], 0)\n",
    "    points = transposed_batch[1]\n",
    "    gt_discretes = torch.stack(transposed_batch[2], 0)\n",
    "    return images, points, gt_discretes\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        self.crop_size = 512\n",
    "        self.data_dir = '../ShanghaiTech/part_A/'\n",
    "        self.lr = 1e-5\n",
    "        self.weight_decay = 1e-4\n",
    "#         self.resume = './Vgglogs/137_ckpt.tar'\n",
    "        self.resume = None\n",
    "\n",
    "        self.max_epoch = 500\n",
    "        self.val_epoch_i = 5\n",
    "        self.val_start = 50\n",
    "        self.sigma = 0.00001\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = 10\n",
    "        self.downsample_ratio = 8\n",
    "        self.norm_cood = 0\n",
    "        self.num_of_iter_in_ot = 100\n",
    "        self.reg = 10\n",
    "        self.wot = 0.1\n",
    "        self.wtv = 0.01\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.save_dir = './Vgglogs'\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "\n",
    "        time_str = datetime.strftime(datetime.now(), '%m%d-%H%M%S')\n",
    "        self.logger = get_logger(os.path.join(self.save_dir, 'train-{:s}.log'.format(time_str)))\n",
    "#         print_config(vars(args), self.logger)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            raise Exception(\"no gpu\")\n",
    "\n",
    "        self.datasets = {'train': Custom_dataloader(os.path.join(self.data_dir, 'train_data'),\n",
    "                                           self.crop_size, self.downsample_ratio, 'train'),\n",
    "                         'val': Custom_dataloader(os.path.join(self.data_dir, 'test_data'),\n",
    "                                         self.crop_size, self.downsample_ratio, 'val'),\n",
    "                         }\n",
    "\n",
    "        self.dataloaders = {x: DataLoader(self.datasets[x],\n",
    "                                          collate_fn=(train_collate\n",
    "                                                      if x == 'train' else default_collate),\n",
    "                                          batch_size=(self.batch_size\n",
    "                                                      if x == 'train' else 1),\n",
    "                                          shuffle=(True if x == 'train' else False),\n",
    "                                          num_workers=self.num_workers ,\n",
    "                                          pin_memory=(True if x == 'train' else False))\n",
    "                            for x in ['train', 'val']}\n",
    "        self.model = vgg19()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        if self.resume:\n",
    "            self.logger.info('loading pretrained model from ' + self.resume)\n",
    "            suf = self.resume.rsplit('.', 1)[-1]\n",
    "#             print('suf: ', suf)\n",
    "            if suf == 'tar':\n",
    "#                 print(\"yo\")\n",
    "                checkpoint = torch.load(self.resume, self.device)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                self.start_epoch = checkpoint['epoch'] + 1\n",
    "#                 print(\"yo again\")\n",
    "\n",
    "            elif suf == 'pth':\n",
    "                self.model.load_state_dict(torch.load(self.resume, self.device))\n",
    "        else:\n",
    "            self.logger.info('random initialization')\n",
    "\n",
    "        self.ot_loss = OT_Loss(self.crop_size, self.downsample_ratio, self.norm_cood, self.device, self.num_of_iter_in_ot,\n",
    "                               self.reg)\n",
    "        self.tv_loss = nn.L1Loss(reduction='none').to(self.device)\n",
    "        self.mse = nn.MSELoss().to(self.device)\n",
    "        self.mae = nn.L1Loss().to(self.device)\n",
    "        self.save_list = Save_Handle(max_num=1)\n",
    "        self.best_mae = np.inf\n",
    "        self.best_mse = np.inf\n",
    "        self.best_count = 0\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.max_epoch + 1):\n",
    "            self.logger.info('-' * 5 + 'Epoch {}/{}'.format(epoch, self.max_epoch) + '-' * 5)\n",
    "            self.epoch = epoch\n",
    "            self.train_eopch()\n",
    "            if epoch % self.val_epoch_i == 0 and epoch >= self.val_start:\n",
    "                self.val_epoch()\n",
    "\n",
    "    def train_eopch(self):\n",
    "        epoch_ot_loss = AverageMeter()\n",
    "        epoch_ot_obj_value = AverageMeter()\n",
    "        epoch_wd = AverageMeter()\n",
    "        epoch_count_loss = AverageMeter()\n",
    "        epoch_tv_loss = AverageMeter()\n",
    "        epoch_loss = AverageMeter()\n",
    "        epoch_mae = AverageMeter()\n",
    "        epoch_mse = AverageMeter()\n",
    "        epoch_start = time.time()\n",
    "        self.model.train()  \n",
    "\n",
    "        for step, (inputs,points , gt_discrete) in enumerate(self.dataloaders['train']):\n",
    "            inputs = inputs.to(self.device)\n",
    "            gd_count = np.array([len(p) for p in points], dtype=np.float32)\n",
    "            points = [p.to(self.device) for p in points]\n",
    "            gt_discrete = gt_discrete.to(self.device)\n",
    "            N = inputs.size(0)\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs, outputs_normed = self.model(inputs)\n",
    "                \n",
    "                ot_loss, wd, ot_obj_value = self.ot_loss(outputs_normed, outputs, points)\n",
    "                ot_loss = ot_loss * self.wot\n",
    "                ot_obj_value = ot_obj_value * self.wot\n",
    "                epoch_ot_loss.update(ot_loss.item(), N)\n",
    "                epoch_ot_obj_value.update(ot_obj_value.item(), N)\n",
    "                epoch_wd.update(wd, N)\n",
    "\n",
    "                count_loss = self.mae(outputs.sum(1).sum(1).sum(1),\n",
    "                                      torch.from_numpy(gd_count).float().to(self.device))\n",
    "                epoch_count_loss.update(count_loss.item(), N)\n",
    "                gd_count_tensor = torch.from_numpy(gd_count).float().to(self.device).unsqueeze(1).unsqueeze(\n",
    "                    2).unsqueeze(3)\n",
    "                gt_discrete_normed = gt_discrete / (gd_count_tensor + 1e-6)\n",
    "                tv_loss = (self.tv_loss(outputs_normed, gt_discrete_normed).sum(1).sum(1).sum(\n",
    "                    1) * torch.from_numpy(gd_count).float().to(self.device)).mean(0) * self.wtv\n",
    "                epoch_tv_loss.update(tv_loss.item(), N)\n",
    "\n",
    "                loss = ot_loss + count_loss + tv_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                pred_count = torch.sum(outputs.view(N, -1), dim=1).detach().cpu().numpy()\n",
    "                pred_err = pred_count - gd_count\n",
    "                epoch_loss.update(loss.item(), N)\n",
    "                epoch_mse.update(np.mean(pred_err * pred_err), N)\n",
    "                epoch_mae.update(np.mean(abs(pred_err)), N)\n",
    "\n",
    "        self.logger.info(\n",
    "            'Epoch {} Train, Loss: {:.2f}, OT Loss: {:.2e}, Wass Distance: {:.2f}, OT obj value: {:.2f}, '\n",
    "            'Count Loss: {:.2f}, TV Loss: {:.2f}, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "                .format(self.epoch, epoch_loss.get_avg(), epoch_ot_loss.get_avg(), epoch_wd.get_avg(),\n",
    "                        epoch_ot_obj_value.get_avg(), epoch_count_loss.get_avg(), epoch_tv_loss.get_avg(),\n",
    "                        np.sqrt(epoch_mse.get_avg()), epoch_mae.get_avg(),\n",
    "                        time.time() - epoch_start))\n",
    "        model_state_dic = self.model.state_dict()\n",
    "        save_path = os.path.join(self.save_dir, '{}_ckpt.tar'.format(self.epoch))\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'model_state_dict': model_state_dic\n",
    "        }, save_path)\n",
    "        self.save_list.append(save_path)\n",
    "\n",
    "    def val_epoch(self):\n",
    "        epoch_start = time.time()\n",
    "        self.model.eval()  # Set model to evaluate mode\n",
    "        epoch_res = []\n",
    "        for inputs, count, name in self.dataloaders['val']:\n",
    "            inputs = inputs.to(self.device)\n",
    "            assert inputs.size(0) == 1, 'the batch size should equal to 1 in validation mode'\n",
    "            with torch.set_grad_enabled(False):\n",
    "                _, outputs = self.model(inputs)\n",
    "                res = count[0].item() - torch.sum(outputs).item()\n",
    "                epoch_res.append(res)\n",
    "\n",
    "        epoch_res = np.array(epoch_res)\n",
    "        mse = np.sqrt(np.mean(np.square(epoch_res)))\n",
    "        mae = np.mean(np.abs(epoch_res))\n",
    "        self.logger.info('Epoch {} Val, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "                         .format(self.epoch, mse, mae, time.time() - epoch_start))\n",
    "\n",
    "        model_state_dic = self.model.state_dict()\n",
    "        if (2.0 * mse + mae) < (2.0 * self.best_mse + self.best_mae):\n",
    "            self.best_mse = mse\n",
    "            self.best_mae = mae\n",
    "            self.logger.info(\"save best mse {:.2f} mae {:.2f} model epoch {}\".format(self.best_mse,\n",
    "                                                                                     self.best_mae,\n",
    "                                                                                     self.epoch))\n",
    "            torch.save(model_state_dic, os.path.join(self.save_dir, 'best_model_{}.pth'.format(self.best_count)))\n",
    "            self.best_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6695a593",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a4908adc1d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480cb4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
