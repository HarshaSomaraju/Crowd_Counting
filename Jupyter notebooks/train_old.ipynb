{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9f0d8c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a82137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31b926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.initial_conv_layers = nn.Sequential(\n",
    "                                nn.Conv2d(3, 16, 9), # x-8\n",
    "                                nn.PReLU(),\n",
    "                                nn.Conv2d(16, 32, 7), # x-8-6 = x-14\n",
    "                                nn.PReLU()\n",
    "                              )\n",
    "        \n",
    "        self.gdf_conv1 = nn.Conv2d(32, 16, 9)\n",
    "        self.gdf_max1 = nn.MaxPool2d(2)\n",
    "        self.gdf_avg1 = nn.AvgPool2d(2)\n",
    "        self.gdf_prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.gdf_conv2 = nn.Conv2d(16, 32, 7)\n",
    "        self.gdf_max2 = nn.MaxPool2d(2)\n",
    "        self.gdf_avg2 = nn.AvgPool2d(2)\n",
    "        self.gdf_prelu2 = nn.PReLU()\n",
    "        \n",
    "        self.gdf_conv3_block = nn.Sequential(\n",
    "                            nn.Conv2d(32, 16, 7, 1, 3), # x-6 + 6 = x\n",
    "                            nn.PReLU(),\n",
    "#                             nn.Conv2d(16, 8, 7, 1, 3), \n",
    "                            nn.Conv2d(16, 8, 6, 1, 4), #Trying to get all WxH same x-5+8 = x+3\n",
    "                            nn.PReLU()\n",
    "                          )\n",
    "        \n",
    "        self.gdf_adp = nn.AdaptiveMaxPool2d((64,64))\n",
    "        self.gdf_adp_prelu = nn.PReLU()\n",
    "        \n",
    "        self.gdf_fc_block = nn.Sequential(\n",
    "            nn.Linear(64*64*8, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(512, 5)\n",
    "        )\n",
    "        \n",
    "        self.cc1_conv1 = nn.Conv2d(32, 20, 7)\n",
    "        self.cc1_max1 = nn.MaxPool2d(2)\n",
    "        self.cc1_avg1 = nn.AvgPool2d(2)\n",
    "        self.cc1_prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.cc1_conv2 = nn.Conv2d(20, 40, 5)\n",
    "        self.cc1_max2 = nn.MaxPool2d(2)\n",
    "        self.cc1_avg2 = nn.AvgPool2d(2)\n",
    "        self.cc1_prelu2 = nn.PReLU()\n",
    "        \n",
    "        self.cc1_conv3_block = nn.Sequential(\n",
    "                            nn.Conv2d(40, 20, 5, 1, 2), # x - 4 + 4 = x\n",
    "                            nn.PReLU(),\n",
    "#                             nn.Conv2d(20, 10, 5, 1, 2), \n",
    "                            nn.Conv2d(20, 10, 4, 1, 2), # Trying to make all WxH same  x-3+4 = x+1\n",
    "                            nn.PReLU()\n",
    "                          )\n",
    "        \n",
    "        \n",
    "        self.cc2_conv1 = nn.Conv2d(32, 24, 5)\n",
    "        self.cc2_max1 = nn.MaxPool2d(2)\n",
    "        self.cc2_avg1 = nn.AvgPool2d(2)\n",
    "        self.cc2_prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.cc2_conv2 = nn.Conv2d(24, 48, 3)\n",
    "        self.cc2_max2 = nn.MaxPool2d(2)\n",
    "        self.cc2_avg2 = nn.AvgPool2d(2)\n",
    "        self.cc2_prelu2 = nn.PReLU()\n",
    "        \n",
    "        self.cc2_conv3_block = nn.Sequential(\n",
    "                            nn.Conv2d(48, 24, 3, 1, 1), # x-2+2 = x\n",
    "                            nn.PReLU(),\n",
    "                            nn.Conv2d(24, 12, 3, 1, 1), #x-2+2 = x\n",
    "                            nn.PReLU()\n",
    "                          )\n",
    "        \n",
    "\n",
    "        self.out_block = nn.Sequential(\n",
    "                        nn.Conv2d(30, 24, 3, 1, 1), # 24, 50-2+2 = 50 (x)\n",
    "                        nn.PReLU(),\n",
    "                        nn.Conv2d(24, 32, 3, 1, 1), # 32, 50-2+2 = 50 (x)\n",
    "                        nn.PReLU(),\n",
    "                        nn.ConvTranspose2d(32, 16, 7, 2, 1, dilation=2), # 16, (50-1)*2 - 2*1 + 1*(3-1) + 1 = 99 (2*x-1)\n",
    "                        nn.PReLU(),\n",
    "                        nn.ConvTranspose2d(16, 8, 6, 2, 1, dilation=2), # 8, (99-1)*2 - 2*1 + 1*(3-1) + 1 = 197 (4*x-3)\n",
    "                        nn.PReLU(),\n",
    "                        nn.Conv2d(8, 8, 1), # 8, 197\n",
    "                        nn.PReLU(),\n",
    "                        nn.Conv2d(8, 1, 1) # 1, 197\n",
    "                    )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial batch_sizex3x225x225\n",
    "#         print(x.shape)\n",
    "        pre_x = self.initial_conv_layers(x)  # 32,225-14 = 211 (x-14)\n",
    "        \n",
    "        # sub task 1\n",
    "        \n",
    "        gd_x = self.gdf_conv1(pre_x) # 211-8 = 16,203 (x-22)\n",
    "        gd_x = self.gdf_max1(gd_x) + self.gdf_avg1(gd_x) # 203/2 = 101 ((x-22)/2)\n",
    "        gd_x = self.gdf_prelu1(gd_x) \n",
    "        \n",
    "        gd_x = self.gdf_conv2(gd_x) # 32,101-6 = 95 ((x-22)/2 - 6) = ((x-34)/2)\n",
    "        gd_x = self.gdf_max2(gd_x) + self.gdf_avg2(gd_x) # 95/2 = 47 ((x-34)/4)\n",
    "        gd_x = self.gdf_prelu2(gd_x) \n",
    "        \n",
    "#         print(\"Before gd_b: \", gd_x.shape)\n",
    "        \n",
    "        gd_out = self.gdf_conv3_block(gd_x) # 8, 47+3 = 50 (x-34/4 + 3 = (x-22/4))\n",
    "        \n",
    "#         print(\"After gd_b: \", gd_out.shape)\n",
    "\n",
    "        \n",
    "        gd_b = self.gdf_adp(gd_out) # 8, 64\n",
    "        gd_b = self.gdf_adp_prelu(gd_b)\n",
    "#         print('Shape after gd adaptive pooling is: ',gd_b.shape)\n",
    "#         gd_b = gd_b.reshape(-1) \n",
    "        gd_b = torch.flatten(gd_b, 1)\n",
    "#         print('Shape after flatten is: ',gd_b.shape)\n",
    "        gd_b = self.gdf_fc_block(gd_b)\n",
    "        \n",
    "        # sub task 2\n",
    "        \n",
    "        # First branch\n",
    "        cc_1 = self.cc1_conv1(pre_x) # 20, 211-6 = 205 (x-20)\n",
    "        cc_1 = self.cc1_max1(cc_1) + self.cc1_avg1(cc_1) # 205/2 = 102 (x-20/2)\n",
    "        cc_1 = self.cc1_prelu1(cc_1)\n",
    "        \n",
    "        cc_1 = self.cc1_conv2(cc_1) # 40, 102-4 = 98 ((x-20)/2 - 4 = (x-28)/2)\n",
    "        cc_1 = self.cc1_max2(cc_1) + self.cc1_avg2(cc_1) # 98/2 = 49 ((x-28)/4)\n",
    "        cc_1 = self.cc1_prelu2(cc_1)\n",
    "        \n",
    "#         print(\"Before cc block: \", cc_1.shape)\n",
    "        \n",
    "        cc_1 = self.cc1_conv3_block(cc_1) # 10, 49+1 = 50\n",
    "#         print(\"cc_1 shape is: \", cc_1.shape)\n",
    "\n",
    "        \n",
    "        # Second branch\n",
    "        cc_2 = self.cc2_conv1(pre_x) # 24, 211-4 = 207 (x-18)\n",
    "        cc_2 = self.cc2_max1(cc_2) + self.cc2_avg1(cc_2) # 207/2 = 103 ((x-18)/2)\n",
    "        cc_2 = self.cc2_prelu1(cc_2)\n",
    "        \n",
    "        cc_2 = self.cc2_conv2(cc_2) # 48, 103-2 = 101 ((x-18)/2 - 2 = (x-22)/2)\n",
    "        cc_2 = self.cc2_max2(cc_2) + self.cc2_avg2(cc_2) # 101/2 = 50 (x-22/4)\n",
    "        cc_2 = self.cc2_prelu2(cc_2)\n",
    "#         print(\"Before cc block: \", cc_2.shape)\n",
    "        \n",
    "        cc_2 = self.cc2_conv3_block(cc_2) # 12, 50\n",
    "        \n",
    "#         print(\"cc_2 shape is: \", cc_2.shape)\n",
    "        \n",
    "#         print(f\"gd_out shape is {gd_out.shape}\\n cc1 shape is {cc_1.shape}\\n cc2 shape is {cc_2.shape}\\n\")\n",
    "        cc_out = torch.cat((gd_out, cc_1, cc_2), dim=1) # 30, 50\n",
    "#         print(\"out shape is: \", cc_out.shape)\n",
    "        out = self.out_block(cc_out)        \n",
    "#         print(\"after out shape is: \", out.shape)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return gd_b, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8e9a3",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0209ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fa6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(im_h, im_w, crop_h, crop_w):\n",
    "    res_h = im_h - crop_h\n",
    "    res_w = im_w - crop_w\n",
    "    i = random.randint(0, res_h)\n",
    "    j = random.randint(0, res_w)\n",
    "    return i, j, crop_h, crop_w\n",
    "\n",
    "\n",
    "def gen_discrete_map(im_height, im_width, points):\n",
    "    \"\"\"\n",
    "        func: generate the discrete map.\n",
    "        points: [num_gt, 2], for each row: [width, height]\n",
    "        \"\"\"\n",
    "    discrete_map = np.zeros([im_height, im_width], dtype=np.float32)\n",
    "    h, w = discrete_map.shape[:2]\n",
    "    num_gt = points.shape[0]\n",
    "    if num_gt == 0:\n",
    "        return discrete_map\n",
    "    \n",
    "    # fast create discrete map\n",
    "    points_np = np.array(points).round().astype(int)\n",
    "    p_h = np.minimum(points_np[:, 1], np.array([h-1]*num_gt).astype('int64'))\n",
    "    p_w = np.minimum(points_np[:, 0], np.array([w-1]*num_gt).astype('int64'))\n",
    "    p_index = torch.from_numpy(p_h* im_width + p_w)\n",
    "#     print('p_index is: ',p_index)\n",
    "    discrete_map = torch.zeros(im_width * im_height).scatter_add_(0, index=p_index, src=torch.ones(im_width*im_height)).view(im_height, im_width).numpy()\n",
    "\n",
    "    ''' slow method\n",
    "    for p in points:\n",
    "        p = np.round(p).astype(int)\n",
    "        p[0], p[1] = min(h - 1, p[1]), min(w - 1, p[0])\n",
    "        discrete_map[p[0], p[1]] += 1\n",
    "    '''\n",
    "    assert np.sum(discrete_map) == num_gt\n",
    "    return discrete_map\n",
    "\n",
    "\n",
    "class Base(data.Dataset):\n",
    "    def __init__(self, root_path, crop_size, downsample_ratio=8):\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.c_size = crop_size\n",
    "        self.d_ratio = downsample_ratio\n",
    "        assert self.c_size % self.d_ratio == 0\n",
    "        self.dc_size = self.c_size // self.d_ratio\n",
    "        self.trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "#             transforms.Resize((225, 225)),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        pass\n",
    "\n",
    "    def train_transform(self, img, keypoints):\n",
    "        wd, ht = img.size\n",
    "        st_size = 1.0 * min(wd, ht)\n",
    "        assert st_size >= self.c_size\n",
    "        assert len(keypoints) >= 0\n",
    "        i, j, h, w = random_crop(ht, wd, self.c_size, self.c_size)\n",
    "        img = F.crop(img, i, j, h, w)\n",
    "        if len(keypoints) > 0:\n",
    "            keypoints = keypoints - [j, i]\n",
    "            idx_mask = (keypoints[:, 0] >= 0) * (keypoints[:, 0] <= w) * \\\n",
    "                       (keypoints[:, 1] >= 0) * (keypoints[:, 1] <= h)\n",
    "            keypoints = keypoints[idx_mask]\n",
    "        else:\n",
    "            keypoints = np.empty([0, 2])\n",
    "\n",
    "        gt_discrete = gen_discrete_map(h, w, keypoints)\n",
    "        down_w = w // self.d_ratio\n",
    "        down_h = h // self.d_ratio\n",
    "        gt_discrete = gt_discrete.reshape([down_h, self.d_ratio, down_w, self.d_ratio]).sum(axis=(1, 3))\n",
    "        assert np.sum(gt_discrete) == len(keypoints)\n",
    "\n",
    "        if len(keypoints) > 0:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "                keypoints[:, 0] = w - keypoints[:, 0]\n",
    "        else:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "        gt_discrete = np.expand_dims(gt_discrete, 0)\n",
    "\n",
    "        return self.trans(img), torch.from_numpy(keypoints.copy()).float(),  len(keypoints), torch.from_numpy(\n",
    "            gt_discrete.copy()).float()\n",
    "    \n",
    "    \n",
    "class Crowd_sh(Base):\n",
    "    def __init__(self, root_path, crop_size,\n",
    "                 downsample_ratio=8,\n",
    "                 method='train'):\n",
    "        super().__init__(root_path, crop_size, downsample_ratio)\n",
    "        self.method = method\n",
    "        if method not in ['train', 'val']:\n",
    "            raise Exception(\"not implement\")\n",
    "\n",
    "        self.im_list = sorted(glob(os.path.join(self.root_path, 'images', '*.jpg')))\n",
    "        print('number of img: {}'.format(len(self.im_list)))\n",
    "        self.denominator = 113.8\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_path = self.im_list[item]\n",
    "        name = os.path.basename(img_path).split('.')[0]\n",
    "        gd_path = os.path.join(self.root_path, 'ground-truth', 'GT_{}.mat'.format(name))\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        keypoints = sio.loadmat(gd_path)['image_info'][0][0][0][0][0]\n",
    "\n",
    "        if self.method == 'train':\n",
    "            return self.train_transform(img, keypoints)\n",
    "        elif self.method == 'val':\n",
    "            img = self.trans(img)\n",
    "            img.resize_((3, 225, 225))\n",
    "            return img, len(keypoints), name\n",
    "\n",
    "    def train_transform(self, img, keypoints):\n",
    "        wd, ht = img.size\n",
    "        st_size = 1.0 * min(wd, ht)\n",
    "        # resize the image to fit the crop size\n",
    "        if st_size < self.c_size:\n",
    "            rr = 1.0 * self.c_size / st_size\n",
    "            wd = round(wd * rr)\n",
    "            ht = round(ht * rr)\n",
    "            st_size = 1.0 * min(wd, ht)\n",
    "            img = img.resize((wd, ht), Image.BICUBIC)\n",
    "            keypoints = keypoints * rr\n",
    "        assert st_size >= self.c_size, print(wd, ht)\n",
    "        assert len(keypoints) >= 0\n",
    "        i, j, h, w = random_crop(ht, wd, self.c_size, self.c_size)\n",
    "        img = F.crop(img, i, j, h, w)\n",
    "        if len(keypoints) > 0:\n",
    "            keypoints = keypoints - [j, i]\n",
    "            idx_mask = (keypoints[:, 0] >= 0) * (keypoints[:, 0] <= w) * \\\n",
    "                       (keypoints[:, 1] >= 0) * (keypoints[:, 1] <= h)\n",
    "            keypoints = keypoints[idx_mask]\n",
    "        else:\n",
    "            keypoints = np.empty([0, 2])\n",
    "\n",
    "        gt_discrete = gen_discrete_map(h, w, keypoints)\n",
    "#         down_w = w // self.d_ratio\n",
    "#         down_h = h // self.d_ratio\n",
    "#         gt_discrete = gt_discrete.reshape([down_h, self.d_ratio, down_w, self.d_ratio]).sum(axis=(1, 3))\n",
    "        assert np.sum(gt_discrete) == len(keypoints)\n",
    "\n",
    "        if len(keypoints) > 0:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "                keypoints[:, 0] = w - keypoints[:, 0] - 1\n",
    "        else:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "                gt_discrete = np.fliplr(gt_discrete)\n",
    "        gt_discrete = np.expand_dims(gt_discrete, 0)\n",
    "        \n",
    "        level = np.round(len(keypoints)/self.denominator)\n",
    "\n",
    "        return self.trans(img), torch.tensor(level).float(), torch.from_numpy(\n",
    "            gt_discrete.copy()).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b6a57",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44279eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb09ef6",
   "metadata": {},
   "source": [
    "###  Helper modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d00ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def get_logger(log_file):\n",
    "    logger = logging.getLogger(log_file)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    fh = logging.FileHandler(log_file)\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    ch.setFormatter(formatter)\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def print_config(config, logger):\n",
    "    \"\"\"\n",
    "    Print configuration of the model\n",
    "    \"\"\"\n",
    "    for k, v in config.items():\n",
    "        logger.info(\"{}:\\t{}\".format(k.ljust(15), v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927859c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, initial_lr=0.001, decay_epoch=10):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = max(initial_lr * (0.1 ** (epoch // decay_epoch)), 1e-6)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class Save_Handle(object):\n",
    "    \"\"\"handle the number of \"\"\"\n",
    "    def __init__(self, max_num):\n",
    "        self.save_list = []\n",
    "        self.max_num = max_num\n",
    "\n",
    "    def append(self, save_path):\n",
    "        if len(self.save_list) < self.max_num:\n",
    "            self.save_list.append(save_path)\n",
    "        else:\n",
    "            remove_path = self.save_list[0]\n",
    "            del self.save_list[0]\n",
    "            self.save_list.append(save_path)\n",
    "            if os.path.exists(remove_path):\n",
    "                os.remove(remove_path)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = 1.0 * self.sum / self.count\n",
    "\n",
    "    def get_avg(self):\n",
    "        return self.avg\n",
    "\n",
    "    def get_count(self):\n",
    "        return self.count\n",
    "\n",
    "\n",
    "def set_trainable(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "\n",
    "\n",
    "def get_num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507a1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate(batch):\n",
    "    transposed_batch = list(zip(*batch))\n",
    "    images = torch.stack(transposed_batch[0], 0)\n",
    "    points = transposed_batch[1]  # the number of points is not fixed, keep it as a list of tensor\n",
    "    gt_discretes = torch.stack(transposed_batch[2], 0)\n",
    "    return images, points, gt_discretes\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        self.crop_size = 225\n",
    "        self.dataset = 'sha'\n",
    "        self.data_dir = '../ShanghaiTech/part_A/'\n",
    "        self.lr = 0.00005\n",
    "        self.weight_decay = 0.0001\n",
    "#         self.resume = './logs/361_ckpt.tar'\n",
    "        self.resume = None\n",
    "\n",
    "        self.max_epoch = 500\n",
    "        self.val_epoch_i = 5\n",
    "        self.val_start = 1\n",
    "        self.sigma = 0.00001\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = 4\n",
    "        self.downsample_ratio = 5\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        self.save_dir = './logs'\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "\n",
    "        time_str = datetime.strftime(datetime.now(), '%m%d-%H%M%S')\n",
    "        self.logger = get_logger(os.path.join(self.save_dir, 'train-{:s}.log'.format(time_str)))\n",
    "#         print_config(vars(args), self.logger)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            self.device_count = torch.cuda.device_count()\n",
    "#             assert self.device_count == 1\n",
    "            self.logger.info('using {} gpus'.format(self.device_count))\n",
    "        else:\n",
    "            raise Exception(\"gpu is not available\")\n",
    "\n",
    "        \n",
    "        if self.dataset.lower() == 'qnrf':\n",
    "            self.datasets = {x: Crowd_qnrf(os.path.join(self.data_dir, x),\n",
    "                                           self.crop_size, self.downsample_ratio, x) for x in ['train', 'val']}\n",
    "        elif self.dataset.lower() == 'nwpu':\n",
    "            self.datasets = {x: Crowd_nwpu(os.path.join(self.data_dir, x),\n",
    "                                           self.crop_size, self.downsample_ratio, x) for x in ['train', 'val']}\n",
    "        elif self.dataset.lower() == 'sha' or self.dataset.lower() == 'shb':\n",
    "            self.datasets = {'train': Crowd_sh(os.path.join(self.data_dir, 'train_data'),\n",
    "                                               self.crop_size, self.downsample_ratio, 'train'),\n",
    "                             'val': Crowd_sh(os.path.join(self.data_dir, 'test_data'),\n",
    "                                             self.crop_size, self.downsample_ratio, 'val'),\n",
    "                             }\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.dataloaders = {x: DataLoader(self.datasets[x],\n",
    "                                          collate_fn=(train_collate\n",
    "                                                      if x == 'train' else default_collate),\n",
    "                                          batch_size=(self.batch_size\n",
    "                                                      if x == 'train' else 1),\n",
    "                                          shuffle=(True if x == 'train' else False),\n",
    "                                          num_workers=self.num_workers * self.device_count,\n",
    "                                          pin_memory=(True if x == 'train' else False))\n",
    "                            for x in ['train', 'val']}\n",
    "        self.model = Network()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.start_epoch = 0\n",
    "        if self.resume:\n",
    "            self.logger.info('loading pretrained model from ' + self.resume)\n",
    "            suf = self.resume.rsplit('.', 1)[-1]\n",
    "#             print('suf: ', suf)\n",
    "            if suf == 'tar':\n",
    "#                 print(\"yo\")\n",
    "                checkpoint = torch.load(self.resume, self.device)\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                self.start_epoch = checkpoint['epoch'] + 1\n",
    "#                 print(\"yo again\")\n",
    "\n",
    "            elif suf == 'pth':\n",
    "                self.model.load_state_dict(torch.load(self.resume, self.device))\n",
    "        else:\n",
    "            self.logger.info('random initialization')\n",
    "\n",
    "#         torch.cdist(a, b, p=2) loss\n",
    "#         self.tv_loss = nn.L1Loss(reduction='none').to(self.device)\n",
    "        self.mse = nn.MSELoss(reduction='sum').to(self.device)\n",
    "        self.cross_entropy = nn.CrossEntropyLoss().to(self.device)\n",
    "        self.save_list = Save_Handle(max_num=1)\n",
    "        self.best_mae = np.inf\n",
    "        self.best_mse = np.inf\n",
    "        self.best_cross_entropy = np.inf\n",
    "        self.best_count = 0\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"training process\"\"\"\n",
    "        for epoch in range(self.start_epoch, self.max_epoch + 1):\n",
    "            self.logger.info('-' * 5 + 'Epoch {}/{}'.format(epoch, self.max_epoch) + '-' * 5)\n",
    "            self.epoch = epoch\n",
    "            self.train_eopch()\n",
    "            if epoch % self.val_epoch_i == 0 and epoch >= self.val_start:\n",
    "                self.val_epoch()\n",
    "\n",
    "    def train_eopch(self):\n",
    "        epoch_level_loss = AverageMeter()\n",
    "\n",
    "        epoch_density_loss = AverageMeter()\n",
    "\n",
    "        epoch_loss = AverageMeter()\n",
    "        epoch_mae = AverageMeter()\n",
    "        epoch_mse = AverageMeter()\n",
    "        epoch_start = time.time()\n",
    "        self.model.train()  # Set model to training mode\n",
    "\n",
    "        for step, (inputs,levels , gt_discrete) in enumerate(self.dataloaders['train']):\n",
    "#             if step==0:\n",
    "#                 plt.imshow(inputs[0].permute(1,2,0))\n",
    "#                 plt.show()\n",
    "#                 plt.imshow(gt_discrete[0].squeeze(0), cmap='gray')\n",
    "#                 plt.show()\n",
    "#             print(\"levels: \", levels)\n",
    "#             print(\"gt: \", gt_discrete)\n",
    "#             print(\"len is: \", torch.sum(gt_discrete))\n",
    "            inputs = inputs.to(self.device)\n",
    "            gt_discrete = gt_discrete.to(self.device)\n",
    "            levels = torch.stack(levels).long().to(self.device)\n",
    "#             print(\"Levels are: \",levels)\n",
    "            N = inputs.size(0)\n",
    "            \n",
    "            gd_count = torch.sum(gt_discrete.view(N, -1), dim=1).detach().cpu().numpy()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                gd_levels, outputs = self.model(inputs)\n",
    "                \n",
    "#                 print('outs: ',outputs)\n",
    "                \n",
    "#                 if step==0:\n",
    "#                     plt.imshow(outputs[0].detach().cpu().squeeze(0), cmap='gray')\n",
    "#                     plt.show()\n",
    "                \n",
    "#                 print(\"outputs shape is: \",outputs.shape)\n",
    "#                 print(\"gt_discrete shape is: \",gt_discrete.shape)\n",
    "\n",
    "                level_loss = self.cross_entropy(gd_levels, levels)\n",
    "                level_loss = level_loss * self.sigma\n",
    "\n",
    "                epoch_level_loss.update(level_loss.item(), N)\n",
    "                \n",
    "                density_loss = self.mse(outputs, gt_discrete)\n",
    "\n",
    "                epoch_density_loss.update(density_loss.item(), N)\n",
    "\n",
    "                loss = density_loss + level_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                pred_count = torch.sum(outputs.view(N, -1), dim=1).detach().cpu().numpy()\n",
    "                pred_err = pred_count - gd_count\n",
    "                epoch_loss.update(loss.item(), N)\n",
    "                epoch_mse.update(np.mean(pred_err * pred_err), N)\n",
    "                epoch_mae.update(np.mean(abs(pred_err)), N)\n",
    "\n",
    "        self.logger.info(\n",
    "            'Epoch {} Train, Loss: {:.2f}, Level Loss: {:.2e}, Density Loss: {:.2f}, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "                .format(self.epoch, epoch_loss.get_avg(), epoch_level_loss.get_avg(), epoch_density_loss.get_avg(),\n",
    "                        np.sqrt(epoch_mse.get_avg()), epoch_mae.get_avg(),\n",
    "                        time.time() - epoch_start))\n",
    "        model_state_dic = self.model.state_dict()\n",
    "        save_path = os.path.join(self.save_dir, '{}_ckpt.tar'.format(self.epoch))\n",
    "        torch.save({\n",
    "            'epoch': self.epoch,\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'model_state_dict': model_state_dic\n",
    "        }, save_path)\n",
    "        self.save_list.append(save_path)\n",
    "\n",
    "    def val_epoch(self):\n",
    "        epoch_start = time.time()\n",
    "        self.model.eval()  # Set model to evaluate mode\n",
    "        epoch_res = []\n",
    "        for inputs, count, name in self.dataloaders['val']:\n",
    "            inputs = inputs.to(self.device)\n",
    "            assert inputs.size(0) == 1, 'the batch size should equal to 1 in validation mode'\n",
    "            with torch.set_grad_enabled(False):\n",
    "                _, outputs = self.model(inputs)\n",
    "                res = count[0].item() - torch.sum(outputs).item()\n",
    "                epoch_res.append(res)\n",
    "\n",
    "        epoch_res = np.array(epoch_res)\n",
    "        mse = np.sqrt(np.mean(np.square(epoch_res)))\n",
    "        mae = np.mean(np.abs(epoch_res))\n",
    "        self.logger.info('Epoch {} Val, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "                         .format(self.epoch, mse, mae, time.time() - epoch_start))\n",
    "\n",
    "        model_state_dic = self.model.state_dict()\n",
    "        if (2.0 * mse + mae) < (2.0 * self.best_mse + self.best_mae):\n",
    "            self.best_mse = mse\n",
    "            self.best_mae = mae\n",
    "            self.logger.info(\"save best mse {:.2f} mae {:.2f} model epoch {}\".format(self.best_mse,\n",
    "                                                                                     self.best_mae,\n",
    "                                                                                     self.epoch))\n",
    "            torch.save(model_state_dic, os.path.join(self.save_dir, 'best_model_{}.pth'.format(self.best_count)))\n",
    "            self.best_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fb0fd2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a4908adc1d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5741c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 21:06:19,277 - INFO - using 1 gpus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of img: 300\n",
      "number of img: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-16 21:06:20,518 - INFO - random initialization\n",
      "2021-05-16 21:06:20,519 - INFO - -----Epoch 0/500-----\n",
      "2021-05-16 21:07:20,100 - INFO - Epoch 0 Train, Loss: 51874.81, Level Loss: 3.87e-04, Density Loss: 51874.81, MSE: 24414.06 MAE: 24241.39, Cost 59.6 sec\n",
      "2021-05-16 21:07:21,300 - INFO - -----Epoch 1/500-----\n",
      "2021-05-16 21:08:23,710 - INFO - Epoch 1 Train, Loss: 43992.93, Level Loss: 1.36e-03, Density Loss: 43992.92, MSE: 20454.85 MAE: 20454.61, Cost 62.4 sec\n",
      "2021-05-16 21:08:24,696 - INFO - -----Epoch 2/500-----\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4db9a43886cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-aa5ff1cde229>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Epoch {}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_eopch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_epoch_i\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-aa5ff1cde229>\u001b[0m in \u001b[0;36mtrain_eopch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mlevel_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel_loss\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[0mepoch_level_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[0mdensity_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_discrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.setup()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7fd718",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12998a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 512\n",
    "dataset = 'sha'\n",
    "data_dir = '../ShanghaiTech/part_A/'\n",
    "lr = 0.001\n",
    "weight_decay = 0.01\n",
    "resume = None\n",
    "max_epoch = 20\n",
    "val_epoch = 5\n",
    "val_start = 4\n",
    "sigma = 0.001\n",
    "num_workers = 1\n",
    "pred_density_map_path = None\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853c1182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of img: 182\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './logs/best_model_1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-22502ffebc47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./logs/best_model_1.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logs/best_model_1.pth'"
     ]
    }
   ],
   "source": [
    "dataset = Crowd_sh(os.path.join(data_dir, 'test_data'), crop_size, 8, method='val')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, 1, shuffle=False,\n",
    "                                         num_workers=1, pin_memory=True)\n",
    "\n",
    "model = Network()\n",
    "model.to('cuda')\n",
    "\n",
    "model_path = './logs/best_model_1.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce054fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "image_errs = []\n",
    "for inputs, count, name in dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    assert inputs.size(0) == 1, 'the batch size should equal to 1'\n",
    "    with torch.set_grad_enabled(False):\n",
    "        _, outputs = model(inputs)\n",
    "    img_err = count[0].item() - torch.sum(outputs).item()\n",
    "\n",
    "    print(name, img_err, count[0].item(), torch.sum(outputs).item())\n",
    "    image_errs.append(img_err)\n",
    "\n",
    "    if pred_density_map_path:\n",
    "        vis_img = outputs[0, 0].cpu().numpy()\n",
    "        # normalize density map values from 0 to 1, then map it to 0-255.\n",
    "        vis_img = (vis_img - vis_img.min()) / (vis_img.max() - vis_img.min() + 1e-5)\n",
    "        vis_img = (vis_img * 255).astype(np.uint8)\n",
    "        vis_img = cv2.applyColorMap(vis_img, cv2.COLORMAP_JET)\n",
    "        cv2.imwrite(os.path.join(args.pred_density_map_path, str(name[0]) + '.png'), vis_img)\n",
    "\n",
    "image_errs = np.array(image_errs)\n",
    "mse = np.sqrt(np.mean(np.square(image_errs)))\n",
    "mae = np.mean(np.abs(image_errs))\n",
    "print('{}: mae {}, mse {}\\n'.format(model_path, mae, mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
